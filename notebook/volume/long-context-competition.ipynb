{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "334e978d-967e-4c2f-b6d4-a9aa88bde10c",
   "metadata": {},
   "source": [
    "## Install Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b3fb392f-8f92-4c57-b329-5a33b2e57f17",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: google-generativeai in /opt/conda/lib/python3.12/site-packages (0.8.3)\n",
      "Requirement already satisfied: google-ai-generativelanguage==0.6.10 in /opt/conda/lib/python3.12/site-packages (from google-generativeai) (0.6.10)\n",
      "Requirement already satisfied: google-api-core in /opt/conda/lib/python3.12/site-packages (from google-generativeai) (2.23.0)\n",
      "Requirement already satisfied: google-api-python-client in /opt/conda/lib/python3.12/site-packages (from google-generativeai) (2.154.0)\n",
      "Requirement already satisfied: google-auth>=2.15.0 in /opt/conda/lib/python3.12/site-packages (from google-generativeai) (2.36.0)\n",
      "Requirement already satisfied: protobuf in /opt/conda/lib/python3.12/site-packages (from google-generativeai) (5.28.3)\n",
      "Requirement already satisfied: pydantic in /opt/conda/lib/python3.12/site-packages (from google-generativeai) (2.9.2)\n",
      "Requirement already satisfied: tqdm in /opt/conda/lib/python3.12/site-packages (from google-generativeai) (4.67.0)\n",
      "Requirement already satisfied: typing-extensions in /opt/conda/lib/python3.12/site-packages (from google-generativeai) (4.12.2)\n",
      "Requirement already satisfied: proto-plus<2.0.0dev,>=1.22.3 in /opt/conda/lib/python3.12/site-packages (from google-ai-generativelanguage==0.6.10->google-generativeai) (1.25.0)\n",
      "Requirement already satisfied: googleapis-common-protos<2.0.dev0,>=1.56.2 in /opt/conda/lib/python3.12/site-packages (from google-api-core->google-generativeai) (1.66.0)\n",
      "Requirement already satisfied: requests<3.0.0.dev0,>=2.18.0 in /opt/conda/lib/python3.12/site-packages (from google-api-core->google-generativeai) (2.32.3)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /opt/conda/lib/python3.12/site-packages (from google-auth>=2.15.0->google-generativeai) (5.5.0)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /opt/conda/lib/python3.12/site-packages (from google-auth>=2.15.0->google-generativeai) (0.4.1)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /opt/conda/lib/python3.12/site-packages (from google-auth>=2.15.0->google-generativeai) (4.9)\n",
      "Requirement already satisfied: httplib2<1.dev0,>=0.19.0 in /opt/conda/lib/python3.12/site-packages (from google-api-python-client->google-generativeai) (0.22.0)\n",
      "Requirement already satisfied: google-auth-httplib2<1.0.0,>=0.2.0 in /opt/conda/lib/python3.12/site-packages (from google-api-python-client->google-generativeai) (0.2.0)\n",
      "Requirement already satisfied: uritemplate<5,>=3.0.1 in /opt/conda/lib/python3.12/site-packages (from google-api-python-client->google-generativeai) (4.1.1)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /opt/conda/lib/python3.12/site-packages (from pydantic->google-generativeai) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.23.4 in /opt/conda/lib/python3.12/site-packages (from pydantic->google-generativeai) (2.23.4)\n",
      "Requirement already satisfied: grpcio<2.0dev,>=1.33.2 in /opt/conda/lib/python3.12/site-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-ai-generativelanguage==0.6.10->google-generativeai) (1.68.0)\n",
      "Requirement already satisfied: grpcio-status<2.0.dev0,>=1.33.2 in /opt/conda/lib/python3.12/site-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-ai-generativelanguage==0.6.10->google-generativeai) (1.68.0)\n",
      "Requirement already satisfied: pyparsing!=3.0.0,!=3.0.1,!=3.0.2,!=3.0.3,<4,>=2.4.2 in /opt/conda/lib/python3.12/site-packages (from httplib2<1.dev0,>=0.19.0->google-api-python-client->google-generativeai) (3.2.0)\n",
      "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /opt/conda/lib/python3.12/site-packages (from pyasn1-modules>=0.2.1->google-auth>=2.15.0->google-generativeai) (0.6.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.12/site-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core->google-generativeai) (3.4.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.12/site-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core->google-generativeai) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.12/site-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core->google-generativeai) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.12/site-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core->google-generativeai) (2024.8.30)\n",
      "Requirement already satisfied: python-dotenv in /opt/conda/lib/python3.12/site-packages (1.0.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install google-generativeai\n",
    "!pip install python-dotenv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dba6f8c9-af07-4ba7-9345-97787e0fbd96",
   "metadata": {},
   "source": [
    "## Import Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d20f8d1f-26b7-4fb4-bca4-75a2dbbf278f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import google.generativeai as genai\n",
    "from dotenv import load_dotenv\n",
    "import threading\n",
    "import time\n",
    "import concurrent"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e423d8b-410f-4f36-9c2b-4aec1f4b500c",
   "metadata": {},
   "source": [
    "## Load API keys\n",
    "NB! to use this model at least 6 google API keys are needed.<br>\n",
    "This can either be done by using `.env` file or inputing them into the code.<br>\n",
    "The env file should be formated like\n",
    "```\n",
    "GOOGLE_API_KEY_1=abc\n",
    "GOOGLE_API_KEY_2=abc\n",
    "GOOGLE_API_KEY_3=abc\n",
    "GOOGLE_API_KEY_4=abc\n",
    "GOOGLE_API_KEY_5=abc\n",
    "GOOGLE_API_KEY_6=abc\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "235c24b7-5e44-4c0c-ac5e-2696c2319551",
   "metadata": {},
   "outputs": [],
   "source": [
    "api_keys = []\n",
    "if os.path.isfile(\".env\"):\n",
    "    load_dotenv()\n",
    "    api_key_1 = os.getenv('GOOGLE_API_KEY_1')\n",
    "    api_key_2 = os.getenv('GOOGLE_API_KEY_2')\n",
    "    api_key_3 = os.getenv('GOOGLE_API_KEY_3')\n",
    "    api_key_4 = os.getenv('GOOGLE_API_KEY_4')\n",
    "    api_key_5 = os.getenv('GOOGLE_API_KEY_5')\n",
    "    api_key_6 = os.getenv('GOOGLE_API_KEY_6')\n",
    "    \n",
    "    api_keys = [\n",
    "        api_key_1,\n",
    "        api_key_2,\n",
    "        api_key_3,\n",
    "        api_key_4,\n",
    "        api_key_5,\n",
    "        api_key_6\n",
    "    ]\n",
    "else:\n",
    "    api_keys = [\n",
    "        \"<GOOGLE_API_KEY_1>\",\n",
    "        \"<GOOGLE_API_KEY_2>\",\n",
    "        \"<GOOGLE_API_KEY_3>\",\n",
    "        \"<GOOGLE_API_KEY_4>\",\n",
    "        \"<GOOGLE_API_KEY_5>\",\n",
    "        \"<GOOGLE_API_KEY_6>\",\n",
    "    ]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a38db85-8aa8-4b82-8868-ccd9e1cf8809",
   "metadata": {},
   "source": [
    "## Loading datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "57109f81-98e6-4b24-9d27-b28f4cfb32c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "filenames = [\n",
    "    \"group_1.txt\",\n",
    "    \"group_2.txt\",\n",
    "    \"group_3.txt\",\n",
    "    \"group_4.txt\",\n",
    "    \"group_5.txt\",\n",
    "    \"group_6.txt\",\n",
    "    \"group_7.txt\",\n",
    "    \"group_8.txt\",\n",
    "    \"group_9.txt\",\n",
    "    \"group_10.txt\",\n",
    "    \"group_11.txt\",\n",
    "    \"group_12.txt\",\n",
    "]\n",
    "file_contents = []\n",
    "for filename in filenames:\n",
    "    file = open(f\"./data/{filename}\", \"r\")\n",
    "    file_content = file.read()\n",
    "    file.close()\n",
    "    file_contents.append(file_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3b735bad-7f05-4393-bacc-db22c7c31b1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def printProgressBar (iteration, total, prefix = '', suffix = '', decimals = 1, length = 100, fill = '█', printEnd = \"\\r\"):\n",
    "    \"\"\"\n",
    "    from: https://stackoverflow.com/questions/3173320/text-progress-bar-in-terminal-with-block-characters\n",
    "    \n",
    "    Call in a loop to create terminal progress bar\n",
    "    @params:\n",
    "        iteration   - Required  : current iteration (Int)\n",
    "        total       - Required  : total iterations (Int)\n",
    "        prefix      - Optional  : prefix string (Str)\n",
    "        suffix      - Optional  : suffix string (Str)\n",
    "        decimals    - Optional  : positive number of decimals in percent complete (Int)\n",
    "        length      - Optional  : character length of bar (Int)\n",
    "        fill        - Optional  : bar fill character (Str)\n",
    "        printEnd    - Optional  : end character (e.g. \"\\r\", \"\\r\\n\") (Str)\n",
    "    \"\"\"\n",
    "    percent = (\"{0:.\" + str(decimals) + \"f}\").format(100 * (iteration / float(total)))\n",
    "    filledLength = int(length * iteration // total)\n",
    "    bar = fill * filledLength + '-' * (length - filledLength)\n",
    "    print(f'\\r{prefix} |{bar}| {percent}% {suffix}', end = printEnd)\n",
    "    # Print New Line on Complete\n",
    "    if iteration == total: \n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c9008463-7b09-463e-bc32-af29375eb7d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "system_prompt = \"Sa oled seaduste abiline. Kui sulle antud seaduses on küsimusele vastust, siis vasta sellele. Kui vastus puudub, siis vasta '0'\"\n",
    "response_format = \"\"\"kastuta vastamisel järgmist formaati:\n",
    "<seaduse nimi>\n",
    "\n",
    "<sinu vastus>\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c6c6bf27",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "thread_local = threading.local()\n",
    "responses_lock = threading.Lock()\n",
    "api_keys_lock = threading.Lock()\n",
    "responses = []\n",
    "\n",
    "\n",
    "def get_session():\n",
    "    if not hasattr(thread_local, \"session\"):\n",
    "        thread_local.session = requests.Session()\n",
    "    return thread_local.session\n",
    "\n",
    "def get_response(data):\n",
    "    api_keys, file_content, group_index, group_count, system_prompt, response_format, question = data\n",
    "    \n",
    "    with api_keys_lock:\n",
    "        if not api_keys:\n",
    "            print(\"No API keys left to process.\")\n",
    "            return\n",
    "        api_key = api_keys.pop(0)\n",
    "        \n",
    "    genai.configure(api_key=api_key)\n",
    "\n",
    "    model = genai.GenerativeModel(\"gemini-1.5-flash\")\n",
    "    if group_index % 2 == 0:\n",
    "        model = genai.GenerativeModel(\"gemini-1.5-flash-8b\")\n",
    "\n",
    "\n",
    "    time.sleep(2)\n",
    "\n",
    "    response_text = model.generate_content([\n",
    "        system_prompt,\n",
    "        response_format,\n",
    "        file_content,\n",
    "        \"Küsimus on järgmine:\",\n",
    "        question\n",
    "    ]).text\n",
    "\n",
    "    # Safely append to the shared responses list\n",
    "    with responses_lock:\n",
    "        responses.append((group_index, response_text))\n",
    "        \n",
    "    groups_done = len(responses)\n",
    "    printProgressBar(groups_done, group_count, length = 50)\n",
    "\n",
    "def get_all_responses(api_keys, file_contents, system_prompt, response_format, question):\n",
    "    group_count = len(api_keys)\n",
    "    tasks = [\n",
    "        ( api_keys, file_contents[i], i, group_count, system_prompt, response_format, question)\n",
    "        for i in range(group_count)\n",
    "    ]\n",
    "\n",
    "    with concurrent.futures.ThreadPoolExecutor(max_workers=6) as executor:\n",
    "        executor.map(get_response, tasks)\n",
    "\n",
    "def contorl_threading(user_message):\n",
    "    temp_api_keys = api_keys.copy()\n",
    "    temp_api_keys = temp_api_keys * 2\n",
    "    temp_api_keys.sort()\n",
    "\n",
    "    start_time = time.time()\n",
    "\n",
    "    group_count = len(api_keys)\n",
    "    printProgressBar(0, group_count, length = 50)\n",
    "\n",
    "    get_all_responses(temp_api_keys, file_contents, system_prompt, response_format, user_message)\n",
    "    \n",
    "    duration = time.time() - start_time\n",
    "\n",
    "    responses.sort(key=lambda x: x[0])\n",
    "\n",
    "    print()\n",
    "    print(f\"Got responses in {duration} seconds\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "882f4be6-304a-4d14-b926-3df5760a6860",
   "metadata": {},
   "outputs": [],
   "source": [
    "for response in responses:\n",
    "    print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ca85e640-f573-447c-bdc1-0e732cf506a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_best_answer(user_message):\n",
    "    genai.configure(api_key=api_keys[0])\n",
    "    model = genai.GenerativeModel(\"gemini-1.5-pro\")\n",
    "    response_texts = [element[1] for element in responses]\n",
    "\n",
    "    print(\"Choosing best answer\")\n",
    "    start_time = time.time()\n",
    "    \n",
    "    prompt = (\n",
    "        [\"Sulle antakse mitme erineva mudeli vastused erinevatest seadustest, tsiteeri mulle mudeli vastuseid, mis pole '0'\"] +\n",
    "        [response_format] +\n",
    "        response_texts + \n",
    "        [\"Küsimus on järgnev:\"] +\n",
    "        [user_message]\n",
    "    )\n",
    "\n",
    "    duration = time.time() - start_time\n",
    "    print(f\"Chose best answer in {duration} seconds\")\n",
    "    \n",
    "    best_answer = model.generate_content(prompt)\n",
    "    return best_answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "08271004-8b57-4d0c-8f81-f4a416a78a35",
   "metadata": {},
   "outputs": [],
   "source": [
    "def full_flow(user_message):\n",
    "    contorl_threading(user_message)\n",
    "    return get_best_answer(user_message).text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82e7f3b3-d34d-4710-bea4-1673f7bbab34",
   "metadata": {},
   "source": [
    "---\n",
    "# Testing chat ui\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51b49ffd-11ee-4e9f-b83c-385cfad1caa8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0;35mChatbot: Hello! Type 'exit' to end the conversation.\u001b[0m\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "You:  Kui palju peab kiiruse ületamise eest trahvi maksma\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " |█████████████████████████-------------------------| 50.0% \n",
      "Got responses in 248.6593677997589 seconds\n",
      "Choosing best answer\n",
      "Chose best answer in 2.6226043701171875e-06 seconds\n",
      "\u001b[0;35mChatbot: <Väärteomenetluse seadustik>\n",
      "\n",
      "Kiiruse ületamise eest trahvi suurust ei ole võimalik kindlaks teha ilma kontekstita.  Seadustik sisaldab kiiruse ületamise eest rahatrahvi määramise üldisi sätteid, ent konkreetne summa sõltub mitmest tegurist, mis on seaduses sätestatud.  Konkreetse kiiruse ületamise väärteo rahatrahvi suuruse määramiseks on vaja teada:  määratud piirkiirus, mitu protsenti ja millise summa võrra on kiiruse norm ületatud.\n",
      "\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import time\n",
    "\n",
    "\n",
    "terminal_colors = {\n",
    "    \"purple\": \"\\033[0;35m\",\n",
    "    \"end\": \"\\033[0m\"\n",
    "}\n",
    "\n",
    "# tell the chatbot what its purpose is about\n",
    "#messages = [\n",
    "#    {\"role\": \"system\", \"content\" : \"\"\"You are my weekly mental health doctor and will help me maintain a positive mindset. \n",
    "#            You will fill me with realistic and optimistic advice to get me through the work week. \n",
    "#            Remember that I work from 9am to 6pm and rest of the day is with my family.\"\"\"}\n",
    "#]\n",
    "\n",
    "def generate_response(user_message):\n",
    "    responses = []\n",
    "    answer = full_flow(user_message)\n",
    "\n",
    "    #messages.append( {\n",
    "    #    \"role\" : \"assistant\",\n",
    "    #    \"content\": answer\n",
    "    #})\n",
    "    return answer\n",
    "\n",
    "print(f\"{terminal_colors['purple']}Chatbot: Hello! Type 'exit' to end the conversation.{terminal_colors['end']}\")\n",
    "\n",
    "while True:\n",
    "    user_input = input(\"You: \")\n",
    "    if user_input.lower() == 'exit':\n",
    "        break\n",
    "    print\n",
    "    response = generate_response(user_input)\n",
    "    print(f\"{terminal_colors['purple']}Chatbot: {response}{terminal_colors['end']}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
